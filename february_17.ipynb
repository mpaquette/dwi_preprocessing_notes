{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DWI preprocessing\n",
    "## using MRTRIX, FSL and ANTS\n",
    "### by Michael Paquette\n",
    "#### Notes from Feb 17th"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this serie of bash notebook, I will be describing a basic DWI data preprocessing pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will try to stick to this (loose) general format to describe each step:  \n",
    "\n",
    "- What is the artefact we are trying to correct or the transformation we are trying to achieve  \n",
    "- Why does this happen  \n",
    "- What would happen if we didnt correct/modify \n",
    "- Why is this step here (somewhat arbitrary or specific ordering)  \n",
    "- Important parameters of the tool (and which one are likely to need finetuning)  \n",
    "- What to look for when doing QC (quality control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Like last time, we setup the basic variable with the folders\n",
      "ROOTDIR='/data/pt_02586/'\n",
      "SUBJECTDIR=$ROOTDIR'sub_01/'\n",
      "# and we move to the preprocessing folder\n",
      "cd $SUBJECTDIR'preprocessing'\n",
      "pwd\n",
      "/data/pt_02586/sub_01/preprocessing\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "# Like last time, we setup the basic variable with the folders\n",
    "ROOTDIR='/data/pt_02586/'\n",
    "SUBJECTDIR=$ROOTDIR'sub_01/'\n",
    "# and we move to the preprocessing folder\n",
    "cd $SUBJECTDIR'preprocessing'\n",
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# We use from now on and forever the NEW bvec\n",
      "# that were created by the EDDY command\n",
      "# because they contain the small rotation\n",
      "# that were introduced by motion correction\n",
      "BVEC=$SUBJECTDIR'preprocessing/dwi_eddy.eddy_rotated_bvecs';\n",
      "BVAL=$SUBJECTDIR'preprocessing/bvals.txt';\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "# We use from now on and forever the NEW bvec\n",
    "# that were created by the EDDY command\n",
    "# because they contain the small rotation\n",
    "# that were introduced by motion correction\n",
    "BVEC=$SUBJECTDIR'preprocessing/dwi_eddy.eddy_rotated_bvecs';\n",
    "BVAL=$SUBJECTDIR'preprocessing/bvals.txt';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Registration with ANTs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use [ANTs (Advanced Normalization Tools)](http://stnava.github.io/ANTs/) for image registration.   \n",
    "\n",
    "In this case, we want to register the FA of our individual subject to an FA atlas in MNI space.  \n",
    "\n",
    "We will use the SyN registration from ANTs, using the command antsRegistrationSyNQuick.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basics of image registration.\n",
    "\n",
    "There is 3 broad \"types\" of registration (sometimes refered to as degrees-of-freedom (dof)):  \n",
    "- **Rigid**: only translations and rotation, data is a \"rigid\" 3D block that gets moved around, (6 dof)  \n",
    "- **Affine**: same as Rigid + uniform stretching, squeezing and shearing (sometimes called linear, 12 dof)  \n",
    "- **\"Nonlinear\"**: Everything else, typically involving complex local deformations.\n",
    "\n",
    "In the case of non-linear registration with ANTs, we first apply a rigid registration to match the images centers and orientation, then an affine registration to match the \"scale/size\" of the image and finally, a SyN registration, which is a specific nonlinear deformation algorithm.  \n",
    "\n",
    "\n",
    "**Moving image**: This is the image that your are registering **TO** something, the one that gets deformed.  \n",
    "**Fixed image**: This is the image that serves as target.  \n",
    "**Warped image**: This is the result of the registration. Its a modified version of the moving image **IN** the space of the fixed image.  \n",
    "**invWarped image**: You can also compute the opposite, i.e. a modified version of the fixed image in the moving space.\n",
    "\n",
    "This is only practical if you have a nice symmetric type of nonlinear registration, one where you can apply the inverse transform. SyN is one such \"well behave\" method.  \n",
    "\n",
    "Typically, the Warped image will also have the resolution of the fixed space.  \n",
    "And the invWarped image will have the resolution of the moving space.  \n",
    "For this reason, it is common to register the lower resolution image **TO** the lower resolution one.  \n",
    "\n",
    "One important **exception** is when we have some anatomical image like a T1 and some diffusion data. In that case, you register the anatomical image to the diffusion space. This is because you cannot apply nonlinear registration to diffusion data without messing up the relation between the images and diffusion b-vectors and you therefore **HAVE** to stay in diffusion native space until you are done with your diffusion local modeling.\n",
    "\n",
    "\n",
    "To recap, in our case here, the moving image is the subject's FA, the fixed image is the MNI template. Therefore, the warped image is our subject warped in MNI space and the invWarped is a deformed template in subject space. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An finetuned usage of ANTs can be quite tricky.  \n",
    "It involve manually setting the parameters of the rigid then the affine and finally the SyN registration.  \n",
    "Choosing for each the number of multi-resolution level, of iteration, the similarity metric, etc.  \n",
    "\n",
    "For example:  \n",
    "```\n",
    " antsRegistration -d 3 \\\n",
    "                  --float 1 \\\n",
    "                  --verbose 1 \\\n",
    "                  -u 1 \\\n",
    "                  -w [ 0.01,0.99 ] \\\n",
    "                  -z 1 \\\n",
    "                  -r [ $fixed,$moving] \\\n",
    "                  -t Rigid[ 0.1 ] \\\n",
    "                  -m MI[$fixed,$moving,1,32,Regular,0.25 ] \\\n",
    "                  -c [ 1000x500x250x0,1e-6,10 ] \\\n",
    "                  -f 6x4x2x1 \\\n",
    "                  -s 4x2x1x0 \\\n",
    "                  -t Affine[ 0.1 ] \\\n",
    "                  -m MI[$fixed,$moving,1,32,Regular,0.25 ] \\\n",
    "                  -c [ 1000x500x250x0,1e-6,10 ] \\\n",
    "                  -f 6x4x2x1 \\\n",
    "                  -s 4x2x1x0 \\\n",
    "                  -t SyN[ 0.1,3,0 ] \\\n",
    "                  -m CC[$fixed,$moving,1,4 ] \\\n",
    "                  -c [ 100x100x70x20,1e-9,10 ] \\\n",
    "                  -f 6x4x2x1 \\\n",
    "                  -s 3x2x1x0 \\\n",
    "                  -o $output\n",
    "```\n",
    "\n",
    "However, we can now use the much more pratical script antsRegistrationSyNQuick.sh  \n",
    "Where the same command would look something like:  \n",
    "\n",
    "```\n",
    "antsRegistrationSyNQuick.sh -d 3 \\\n",
    "    -p f \\\n",
    "    -f $fixed \\\n",
    "    -m $moving \\\n",
    "    -o $output \\\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters\n",
    "\n",
    "We need to specify the fixed (-f) and moving (-m) image, an output prefix name (-o) and specify 3D registration (-d).  \n",
    "\n",
    "The only other relevant option for us is the number of cpu for parallelisation (-n).  \n",
    "\n",
    "We leave the type of transform (-t) to the default for rigid+affine+SyN.  \n",
    "We are using already masked data instead of a mask.  \n",
    "\n",
    "#### outputs\n",
    "\n",
    "This tools will ouput 5 files (all starting with the output prefix (-o)):  \n",
    "- 0GenericAffine.mat: This is a matrix containing the rigid+affine parameter of the registration from moving to fixed.  \n",
    "- 1Warp.nii.gz: This is a warp-image containing the nonlinear part of the registration from moving to fixed.  \n",
    "- Warped.nii.gz: This is the warped image, i.e. the moving image deformed into the fixed space.  \n",
    "- 1InverseWarp.nii.gz: This is another warp-image containing the inverse of the nonlinear part of the registration, i.e. it is a warp-image to bring fixed to moving.  \n",
    "- InverseWarped.nii.gz: This is the invWarped image, i.e. the fixed image deformed into the moving space.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "antsRegistrationSyNQuick.sh -h\n",
      "\n",
      "Usage:\n",
      "\n",
      "antsRegistrationSyNQuick.sh -d ImageDimension -f FixedImage -m MovingImage -o OutputPrefix\n",
      "\n",
      "Example Case:\n",
      "\n",
      "antsRegistrationSyNQuick.sh -d 3 -f fixedImage.nii.gz -m movingImage.nii.gz -o output\n",
      "\n",
      "Compulsory arguments:\n",
      "\n",
      "     -d:  ImageDimension: 2 or 3 (for 2 or 3 dimensional registration of single volume)\n",
      "\n",
      "     -f:  Fixed image(s) or source image(s) or reference image(s)\n",
      "\n",
      "     -m:  Moving image(s) or target image(s)\n",
      "\n",
      "     -o:  OutputPrefix: A prefix that is prepended to all output files.\n",
      "\n",
      "Optional arguments:\n",
      "\n",
      "     -n:  Number of threads (default = ITK_GLOBAL_DEFAULT_NUMBER_OF_THREADS if defined, otherwise 1)\n",
      "\n",
      "     -i:  initial transform(s) --- order specified on the command line matters\n",
      "\n",
      "     -t:  transform type (default = 's')\n",
      "        t: translation (1 stage)\n",
      "        r: rigid (1 stage)\n",
      "        a: rigid + affine (2 stages)\n",
      "        s: rigid + affine + deformable syn (3 stages)\n",
      "        sr: rigid + deformable syn (2 stages)\n",
      "        so: deformable syn only (1 stage)\n",
      "        b: rigid + affine + deformable b-spline syn (3 stages)\n",
      "        br: rigid + deformable b-spline syn (2 stages)\n",
      "        bo: deformable b-spline syn only (1 stage)\n",
      "\n",
      "     -r:  histogram bins for mutual information in SyN stage (default = 32)\n",
      "\n",
      "     -s:  spline distance for deformable B-spline SyN transform (default = 26)\n",
      "\n",
      "     -x:  mask(s) for the fixed image space.  Should specify either a single image to be used for\n",
      "          all stages or one should specify a mask image for each \"stage\" (cf -t option).  If\n",
      "          no mask is to be used for a particular stage, the keyword 'NULL' should be used\n",
      "          in place of a file name.\n",
      "\n",
      "     -p:  precision type (default = 'd')\n",
      "        f: float\n",
      "        d: double\n",
      "\n",
      "     -j:  use histogram matching (default = 0)\n",
      "        0: false\n",
      "        1: true\n",
      "\n",
      "     -z:  collapse output transforms (default = 1)\n",
      "\n",
      "     -e:  Fix random seed to an int value (default = system time)\n",
      "\n",
      "     NB:  Multiple image pairs can be specified for registration during the SyN stage.\n",
      "          Specify additional images using the '-m' and '-f' options.  Note that image\n",
      "          pair correspondence is given by the order specified on the command line.\n",
      "          Only the first fixed and moving image pair is used for the linear resgitration\n",
      "          stages.\n",
      "\n",
      "--------------------------------------------------------------------------------------\n",
      "Get the latest ANTs version at:\n",
      "--------------------------------------------------------------------------------------\n",
      "https://github.com/stnava/ANTs/\n",
      "\n",
      "--------------------------------------------------------------------------------------\n",
      "Read the ANTS documentation at:\n",
      "--------------------------------------------------------------------------------------\n",
      "http://stnava.github.io/ANTs/\n",
      "\n",
      "--------------------------------------------------------------------------------------\n",
      "ANTS was created by:\n",
      "--------------------------------------------------------------------------------------\n",
      "Brian B. Avants, Nick Tustison and Gang Song\n",
      "Penn Image Computing And Science Laboratory\n",
      "University of Pennsylvania\n",
      "\n",
      "Relevent references for this script include:\n",
      "   * http://www.ncbi.nlm.nih.gov/pubmed/20851191\n",
      "   * http://www.frontiersin.org/Journal/10.3389/fninf.2013.00039/abstract\n",
      "--------------------------------------------------------------------------------------\n",
      "script by Nick Tustison\n",
      "--------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "antsRegistrationSyNQuick.sh -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# In pratice, we have the MNI template\n",
      "ta/standard/FSL_HCP1065_FA_1mm.nii.gz'0.3/ubuntu-bionic-amd64/dat\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "# In pratice, we have the MNI template\n",
    "MNIFA='/afs/cbs.mpg.de/software/fsl/6.0.3/ubuntu-bionic-amd64/data/standard/FSL_HCP1065_FA_1mm.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple 3D registration with the MNI FA template as fixed,\n",
    "# our previously created masked subject FA as the moving\n",
    "# some output name\n",
    "# and 20 cpu for faster processing.\n",
    "antsRegistrationSyNQuick.sh -d 3 \\\n",
    "    -f $MNIFA \\\n",
    "    -m $MASKEDFAANTS \\\n",
    "    -o fa_eddy \\\n",
    "    -n 20;\n",
    "\n",
    "# Which will output:\n",
    "# part 1 of the transform \"fa_eddy0GenericAffine.mat\"\n",
    "# part 2 of the transform \"fa_eddy1Warp.nii.gz\"\n",
    "# part 2 of the inverse transform \"fa_eddy1InverseWarp.nii.gz\"\n",
    "# subject FA in MNIspace \"fa_eddyWarped.nii.gz\"\n",
    "# template in subject space \"fa_eddyInverseWarped.nii.gz\"\n",
    "\n",
    "# Note that there is no InverseGenericAffine.mat because the inverse of an affine matrix is simply the inverse matrix.\n",
    "# The tools handle this by themself with and \"inverse affine\" option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case, we don't actually care about the deformed subject image in template space, we actually only wanted the inverse transform whcih we can apply to anything that \"lives\" in MNI space and bring it into subject specific space.  \n",
    "\n",
    "In our case, we have seeding coordinates in MNI space that were used to create rough seeding ROI in MNI space whcih can be \"imported\" into subject space by properly applying the inverse transform with antsApplyTransforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "antsApplyTransforms -h\n",
      "\n",
      "COMMAND: \n",
      "     antsApplyTransforms\n",
      "\n",
      "OPTIONS: \n",
      "     -d, --dimensionality 2/3/4\n",
      "     -e, --input-image-type 0/1/2/3/4 \n",
      "                            scalar/vector/tensor/time-series/multichannel \n",
      "     -i, --input inputFileName\n",
      "     -r, --reference-image imageFileName\n",
      "     -o, --output warpedOutputFileName\n",
      "                  [warpedOutputFileName or compositeDisplacementField,<printOutCompositeWarpFile=0>]\n",
      "                  Linear[genericAffineTransformFile,<calculateInverse=0>]\n",
      "     -n, --interpolation Linear\n",
      "                         NearestNeighbor\n",
      "                         MultiLabel[<sigma=imageSpacing>,<alpha=4.0>]\n",
      "                         Gaussian[<sigma=imageSpacing>,<alpha=1.0>]\n",
      "                         BSpline[<order=3>]\n",
      "                         CosineWindowedSinc\n",
      "                         WelchWindowedSinc\n",
      "                         HammingWindowedSinc\n",
      "                         LanczosWindowedSinc\n",
      "                         GenericLabel[<interpolator=Linear>]\n",
      "     -u, --output-data-type char\n",
      "                            uchar\n",
      "                            short\n",
      "                            int\n",
      "                            float\n",
      "                            double\n",
      "                            default\n",
      "     -t, --transform transformFileName\n",
      "                     [transformFileName,useInverse]\n",
      "     -f, --default-value value\n",
      "     -z, --static-cast-for-R value\n",
      "     --float \n",
      "     -v, --verbose (0)/1\n",
      "     -h \n",
      "     --help \n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "antsApplyTransforms -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using antsApplyTransforms with the result of the previous registration\n",
    "# to bring some ROI image from MNI space to subject space\n",
    "# -i: the ROI image to be warped\n",
    "# -r: A reference image, something which is already in subject space\n",
    "# it will also define the resolution of the warped image\n",
    "# -t: a transform to be applied\n",
    "# !!!! the order of the transforms matter,\n",
    "# it is a stack, therefore it applies the transforms in reverse of reading order.\n",
    "# For the case here, it first apply the second -t which is the InverseWarp\n",
    "# Then it apply the inverse of the affine (notice the \"1\" next to the affine, indicating to useInverse)\n",
    "# -o: output name for the transformed image\n",
    "antsApplyTransforms -d 3 \\\n",
    "    -i $ROOTDIR'ROI_MNI/ifgop_peak_dilx2.nii.gz' \\\n",
    "    -r $SUBJECTDIR'preprocessing/fa_post_eddy.nii.gz' \\\n",
    "    -t [$SUBJECTDIR'preprocessing/fa_eddy0GenericAffine.mat', 1] \\\n",
    "    -t $SUBJECTDIR'preprocessing/fa_eddy1InverseWarp.nii.gz' \\\n",
    "    -o $SUBJECTDIR'preprocessing/ifgop_peak_dilx2_warped.nii.gz';\n",
    "\n",
    "\n",
    "# If we were instead trying to tranform some other subject map into MNI space, \n",
    "# we would first put -t 1Warp.nii.gz and then -t 0GenericAffine.mat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We'll discuss the specific of the MNI ROI creation when dealing with tractography next week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diffusion Local Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The diffusion signal intensity is inversely proportional to the \"amount of diffusion\" in a given direction.  \n",
    "- In our protocol, We have a lot of diffusion directions to \"sample\" this signal on the sphere.  \n",
    "\n",
    "This signal on the sphere can be transformed into a **diffusion orientation distribution function (dODF)**, typically represented as a deformed sphere which represent the \"amount of diffusion\" at all orientations.  \n",
    "\n",
    "- There is more diffusion along the orientation of WM bundles then across because it is easier (less obstacles) for water molecule to move in that directions.  \n",
    "- Therefore, the maximas of the dODF should match bundle orienation.  \n",
    "- However, there is still some diffusion in other orientations.  \n",
    "\n",
    "This is why we want to create a **fiber orientation distribution function (fODF or FOD)** which is an object representing the \"probabilities\" or \"proportion\" of fiber at all orientation instead.  \n",
    "\n",
    "This is very similar to the dODF but with sharper peak and it is therefore the prefered object for tractography.  \n",
    "\n",
    "The idea is to estimate what the **dODF** looks like for voxel with only a single very well alligned bundle (no crossing, no fanning).  \n",
    "We then use that special single bundle dODF (called response function) to **deconvolve** all the dODF in the brain and therefore compute de fODF. You can think of decovolution as a de-blurring on the sphere.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use \"dwi2response\" and \"dwi2fod\" from MRTRIX to estimate the response function and compute the fODF. \n",
    "This model is called constrained spherical deconvolution (CSD).  \n",
    "\n",
    "And important detail of CSD is that it first fits a spherical harmonics (SH) to represent the signal, instead of working directly on the discrete bvec samples. We have to set a maximum order for the SH basis (-lmax) which will depend on the number of bvecs we have.  \n",
    "The most common choice is lmax=8 (or sh order 8) but this requires 45+ bvecs to be well defined (i.e. the SH basis of order maximum 8 has 45 degree-of-freedom).  \n",
    "Here we have 30 bvecs, we will therefore use lmax=6 (28 dof).\n",
    "The generic formula for the number of dof of SH basis lmax is $$\\frac{(l_\\max+1)(l_\\max+2)}{2}$$  \n",
    "\n",
    "But in practice, you wouldnt want to use more than lmax=8 even if you have tons bvecs and you wouldnt be using CSD if you have less than 30 bvecs, so it's pretty much always order 8 or 6.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# command to estimate the single-fiber response function\n",
    "# we use the fa method here which is simple and works well for in-vivo single bvalue\n",
    "# This command will find the highest FA voxel inside a mask, align them and fit the SH.\n",
    "# parameters:\n",
    "# diffusion data\n",
    "# file name to store the response function\n",
    "# -fslgrad: bvecs and bvals\n",
    "# -mask: (we dont want to include \"artefact\" voxels outside the brain as potential candidate)\n",
    "# Here the mask is a tight brain mask with an FA threshold\n",
    "# -voxels: file name to save a mask of which voxels where selected as single fiber population\n",
    "# -lmax: SH basis order for the response function, this should always be 4\n",
    "# -ntheads: number of cpu for faster computation\n",
    "# -number: the number of single fiber voxel to use\n",
    "dwi2response fa \\\n",
    "    dwi_eddy.nii.gz \\\n",
    "    response_fa.txt \\\n",
    "    -fslgrad $BVEC $BVAL \\\n",
    "    -mask fa_eddy_th0p3.nii.gz \\\n",
    "    -voxels response_voxel_fa.nii.gz \\\n",
    "    -lmax 4 \\\n",
    "    -nthreads 20 \\\n",
    "    -number 300;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can visually inspect the response function with the following command:\n",
    "shview response_fa.txt\n",
    "# It should look like a puffy disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# command to compute csd on the brain\n",
    "# we specify csd as the model since we are using single bvalue data\n",
    "# parameters: \n",
    "# diffusion data\n",
    "# the response function\n",
    "# file name to save the FOD (it is saved as SH coefficients)\n",
    "# -fslgrad: bvecs and bvals\n",
    "# -mask: Here I am using a larger mask than for the response function (a BET mask)\n",
    "# This is because I want to make sure I have an FOD everywhere, including low FA voxels\n",
    "# (such has crossing or near cortex sometimes)\n",
    "# -ntheads: number of cpu for faster computation\n",
    "# -lmax: SH basis discused before, this depends on the number of bvec\n",
    "dwi2fod csd \\\n",
    "    dwi_eddy.nii.gz \\\n",
    "    response_fa.txt \\\n",
    "    fod_lmax6.nii.gz \\\n",
    "    -fslgrad $BVEC $BVAL \\\n",
    "    -mask b0_eddy_avg_N4x3_bet_0p4_mask.nii.gz \\\n",
    "    -nthreads 20 \\\n",
    "    -lmax 6;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
