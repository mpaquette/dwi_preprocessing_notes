{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DWI preprocessing\n",
    "## using MRTRIX, FSL and ANTS\n",
    "### by Michael Paquette\n",
    "#### Notes from Jan 20th"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this serie of bash notebook, I will be describing a basic DWI data preprocessing pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will try to stick to this (loose) general format to describe each step:  \n",
    "\n",
    "- What is the artefact we are trying to correct or the transformation we are trying to achieve  \n",
    "- Why does this happen  \n",
    "- What would happen if we didnt correct/modify \n",
    "- Why is this step here (somewhat arbitrary or specific ordering)  \n",
    "- Important parameters of the tool (and which one are likely to need finetuning)  \n",
    "- What to look for when doing QC (quality control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Like last time, we setup the basic variable with the folders\n",
      "ROOTDIR='/data/pt_02586/'\n",
      "SUBJECTDIR=$ROOTDIR'sub_01/'\n",
      "# and we move to the preprocessing folder\n",
      "cd $SUBJECTDIR'preprocessing'\n",
      "pwd\n",
      "/data/pt_02586/sub_01/preprocessing\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "# Like last time, we setup the basic variable with the folders\n",
    "ROOTDIR='/data/pt_02586/'\n",
    "SUBJECTDIR=$ROOTDIR'sub_01/'\n",
    "# and we move to the preprocessing folder\n",
    "cd $SUBJECTDIR'preprocessing'\n",
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BVEC=$SUBJECTDIR'preprocessing/bvecs.txt';\n",
      "BVAL=$SUBJECTDIR'preprocessing/bvals.txt';\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "BVEC=$SUBJECTDIR'preprocessing/bvecs.txt';\n",
    "BVAL=$SUBJECTDIR'preprocessing/bvals.txt';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DTI fit for QC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing a quick DTI fit and FA map is useful for QC.  \n",
    "The DTI glyph are used to identify mismatch between the bvecs orientation and the data orientation  \n",
    "The FA can be used to detect large anomaly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1: Look at tensor glyph for inconsistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DTI/FA on non-eddy corrected data\n",
    "dwi2tensor $SUBJECTDIR'preprocessing/dwi_denoise_degibbs.nii.gz' \\\n",
    "    $SUBJECTDIR'preprocessing/dti_quick.nii.gz' \\\n",
    "    -fslgrad $BVEC $BVAL\n",
    "\n",
    "tensor2metric $SUBJECTDIR'preprocessing/dti_quick.nii.gz' \\\n",
    "    -fa $SUBJECTDIR'preprocessing/fa_quick.nii.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2: Use dwigradcheck\n",
    "The dwigradcheck tool from MRtrix tries all possible permutation of the bvec and computes a few streamlines for each.  \n",
    "Which ever orientation / flip produces the longuest streamline on average is chosen.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I have manually produced various types of bad bvec to showcase the tool ability to detect them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no flip\n",
    "dwigradcheck dwi_denoise_degibbs.nii.gz \\\n",
    "    -mask mask_for_eddy.nii.gz \\\n",
    "    -fslgrad bvecs bvals \\\n",
    "    -export_grad_fsl bvecs_noflip_corrected bvals_noflip_corrected \\\n",
    "    -number 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x-flip (wrong sign on x axis of the bvec)\n",
    "dwigradcheck dwi_denoise_degibbs.nii.gz \\\n",
    "    -mask mask_for_eddy.nii.gz \\\n",
    "    -fslgrad bvecs_xflip bvals \\\n",
    "    -export_grad_fsl bvecs_xflip_corrected bvals_xflip_corrected \\\n",
    "    -number 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y-flip (wrong sign on x axis of the bvec)\n",
    "dwigradcheck dwi_denoise_degibbs.nii.gz \\\n",
    "    -mask mask_for_eddy.nii.gz \\\n",
    "    -fslgrad bvecs_yflip bvals \\\n",
    "    -export_grad_fsl bvecs_yflip_corrected bvals_yflip_corrected \\\n",
    "    -number 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-flip (wrong sign on x axis of the bvec)\n",
    "dwigradcheck dwi_denoise_degibbs.nii.gz \\\n",
    "    -mask mask_for_eddy.nii.gz \\\n",
    "    -fslgrad bvecs_zflip bvals \\\n",
    "    -export_grad_fsl bvecs_zflip_corrected bvals_zflip_corrected \\\n",
    "    -number 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Susceptibility-induced off-resonance distorsion correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are we correcting?\n",
    "Image distorsion at the brain boundaries.  \n",
    "#### Why does this happen?\n",
    "Diffusion imaging is typically performed using diffusion weighted spin-echo EPI (echo-planar imaging) images. These images will be very sensitive to non-zero off-resonance fields. Such fields will be caused by the susceptibility distribution of the subjects head (known as a susceptibility-induced off-resonance field).    \n",
    "#### What if we ignore it?\n",
    "In the typical case, where the phase encoding direction is AP, we will have large distorsion mainly at the front of the brain.  \n",
    "#### Why correct it now?\n",
    "This step can be performed at any moment before the EDDY step since it uses its own image for the estimation (at least one pair of AP and PA aquired b0).  \n",
    "#### correction tool: topup\n",
    "topup is the FSL tool to estimate the suceptibility induced distorsion.  \n",
    "It takes in at least one pair of specially acquired b0 images with opposing phase encoding direction, for example AP and PA. It also required the phase encoding direction table that we extracted from the DICOMs at the very begining (we used the flag '-export_pe_table' with mrconvert and saved pe_table.txt)  \n",
    "This pair of image as opposite types of suceptibility-induced distorsion and the tool computes a local deformation map that is consistent with both image and bring them on top of each other.  \n",
    "Topup has a lots of parameters that are way too often ignored. The parameters are typically \"hidden\" inside a configuration file (more later).  \n",
    "#### Quality control\n",
    "- The AP and PA image after topup should overlap, if the distorsion looks worse, there was probably a sign wrong in the pe_table or the AP image was identified as the PA one and vice-versa (rare type of error). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is common to have the AP and PA aquisition as two separate files,\n",
    "# so we need to concatenate the pe_table and the images\n",
    "mrcat -axis 3 b0_AP.nii.gz b0_PA.nii.gz b0_AP_PA.nii.gz\n",
    "cat pe_table_AP.txt pe_table_PA.txt > pe_table_AP_PA.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the typical topup call\n",
    "# --imain: the input AP Pa image\n",
    "# --datain: the pe_table\n",
    "# --out: a prefix name for all the topup output files\n",
    "# --iout: a name for the topup corrected b0_AP_PA image\n",
    "# --config: a file with the rest of the parameters\n",
    "topup --imain=b0_AP_PA.nii.gz \\\n",
    "      --datain=pe_table_AP_PA.txt \\\n",
    "      --out=topup_ \\\n",
    "      --iout=b0_topup.nii.gz \\\n",
    "      --config=b02b0_mod.cnf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat /data/pt_02586/processing_tutorial/b02b0_mod.cnf\n",
      "# Resolution (knot-spacing) of warps in mm\n",
      "--warpres=24.0,20.0,16.0,12.0,8.0,6.0,4.0,2.0\n",
      "# Subsampling level (a value of 2 indicates that a 2x2x2 neighbourhood is collapsed to 1 voxel)\n",
      "--subsamp=2,2,2,2,1,1,1,1\n",
      "# FWHM of gaussian smoothing\n",
      "--fwhm=4,3,3,2,1,0,0,0\n",
      "# Maximum number of iterations\n",
      "--miter=5,5,5,5,10,10,10,10\n",
      "# Relative weight of regularisation\n",
      "--lambda=0.001,0.0001,0.000015,0.000005,0.0000005,0.00000005,0.00000005,0.000000005\n",
      "# If set to 1 lambda is multiplied by the current average squared difference\n",
      "--ssqlambda=1\n",
      "# Regularisation model\n",
      "--regmod=bending_energy\n",
      "# If set to 1 movements are estimated along with the field\n",
      "--estmov=1,1,1,1,0,0,0,0\n",
      "# 0=Levenberg-Marquardt, 1=Scaled Conjugate Gradient\n",
      "--minmet=0,0,0,0,1,1,1,1\n",
      "# Quadratic or cubic splines\n",
      "--splineorder=3\n",
      "# Precision for calculation and storage of Hessian\n",
      "--numprec=double\n",
      "# Linear or spline interpolation\n",
      "--interp=spline\n",
      "# If set to 1 the images are individually scaled to a common mean intensity \n",
      "--scale=1"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "cat /data/pt_02586/processing_tutorial/b02b0_mod.cnf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First note on the config files, topup is algorithm that make use of \"multi-resolution\", i.e. it does something at a coarse resolution because its fast, then it starts from the coarse solution and solves it again at better resolution using the fact that its faster to solve the high resolution case with the \"hot start\" solution from the coarse case.  \n",
    "It keeps doing this more and more until we reach the resolution of the data.  \n",
    "This is why all the parameters are 8 comma separated values in this case, they are the values for each resolution of the multi-resolution.  \n",
    "Typically, you don't need/want to change this file much, the only really important aspects are:  \n",
    "- same numbers of \"step\" for all the parameters  \n",
    "- you want at least the last steps of \"--subsamp\" to be 1\n",
    "- you want at least the last step of '--fwhm' to be 0  \n",
    "- you want the last step of '--warpres' to be the data's resolution\n",
    "- you want ALL the numbers in '--warpres' to be multiples of the data resolution (if data is 1.7mm, you want something like 20.4, 17.0, 13.6, 10.2, 6.8, 5.1, 3.4, 1.7 )\n",
    "\n",
    "more info at https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/topup/TopupUsersGuide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the topup estimation from the b0s, you can use the \"applytopup\" command to apply the same correction to all your dwi images, since they all have approximatively the same distorsions.  \n",
    "However, we can do better. The next tool that we will use (eddy) has to option to take the topup field estimation as a parameter, and use it within it's own computation and output the fully corrected data.  \n",
    "This is better since we don't need to run applytopup ourself and it reduces the total number of interpolation applied to our data (because the topup and eddy step are combined)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eddy current distorsion corrections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are we correcting?\n",
    "Image distorsion on each DWI volumes.    \n",
    "#### Why does this happen?\n",
    "The diffusion gradient (the physical gradient system on the machine, not the bvecs) create \"accidental\" extra magnetic field call eddy currents (https://en.wikipedia.org/wiki/Eddy_current) which translate into spatial image distorsion that depend on diffusion direction.     \n",
    "#### What if we ignore it?\n",
    "Mismatch between the different diffusion directions, especially visible at the brain edges and cotex.  \n",
    "#### Why correct it now?\n",
    "This step will require interpolation of the data and therefore need to be applied after the raw image correction such as denoising and degibbsing. The tool also requires the previously computed brain mask. Also, this tool can incorporate the previous topup correction.   \n",
    "#### correction tool: eddy\n",
    "eddy is the FSL tool to estimate and correct the eddy current induced distorsion. It also estimate and correct for subject motion.  \n",
    "Eddy uses the fact that dwi with approximatively inverse bvec directions (like (x y z) and (-x -y -z) ) have approximatively the same diffusion contrast (diffusion is antipodally symmetric) but different eddy-current induced distorsions.  \n",
    "It works optimally when the set of bvec direction is design to span a full sphere instead of just half a sphere (which is sadly common, because of the antipodal symmetry).  \n",
    "Similar to topup, its uses two parameters textfile that we obtained from the initial dicom conversion (the eddy indices and the eddy index).  \n",
    "The parameters are fairly self explanatory appart from:  \n",
    "- \"--data_is_shelled\" flag which tells eddy that our data lives a shell of the same bvalue. This flag is neccesary because sometimes the bvals are slightly different between the dwi because of rounding and this will confuse eddy if we dont force it to consider it as a single bval shell.  \n",
    "- \"--dont_peas\" flag which tell eddy not to run the \"Post Eddy Alignment of Shells\" which is a type of registration between the shells when you have multiple bvalues which I don't find very useful or stable.\n",
    "\n",
    "#### Quality control\n",
    "- When scrolling through the diffusion images, they should \"move\" less then before, both because of the motion correction and the eddy current distorsion correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eddy is a VERY computationally expensive step\n",
    "# The regular version of eddy is very slow\n",
    "# However, there exist a version called eddy_openmp\n",
    "# eddy_openmp is a multithreaded eddy version (parallel)\n",
    "# there is also a cuda version (eddy_cuda8.0 in this case)\n",
    "# which is a gpu implementation and its very fast if you have the hardware\n",
    "# for example, on the ramones cluster at the mpi\n",
    "# using the \"CUDA --version 8.0\" environement\n",
    "# running eddy only takes 1-2 hours on a typical dataset\n",
    "# sadly, you will have to figure out with your IT dept how to install this\n",
    "# on whatever compute environement you use\n",
    "# see \"The eddy executables\" section on\n",
    "# https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/eddy/UsersGuide\n",
    "p_EDDY=/data/pt_02101_dMRI/software/eddy/eddy_cuda8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first step is to take the optimal brain mask we previously computed\n",
    "# In this case, the optimal threshold was store in a textfile betthforeddy.txt\n",
    "# so I \"build\" the name of the file using that textfile\n",
    "# after that, I apply 1 dilatation to this mask to make it a bit more permissive\n",
    "maskfilter $SUBJECTDIR'preprocessing/b0_avg_N4x3_bet_init_0p'$( cat $SUBJECTDIR'preprocessing/betthforeddy.txt' )'_mask.nii.gz' \\\n",
    "    dilate \\\n",
    "    $SUBJECTDIR'preprocessing/mask_for_eddy.nii.gz' \\\n",
    "    -npass 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eddy command\n",
    "# it requires the data, the mask, the bval and bvec\n",
    "# the special parameter textfile eddy indices and eddy config\n",
    "# also, a name for all the output \"-out\"\n",
    "# optionally, IF we had previously computed topup,\n",
    "# there is a '--topup' parameter to give it the name used for the output\n",
    "# for example \"topup_\"\n",
    "${p_EDDY} --imain=$SUBJECTDIR'preprocessing/dwi_denoise_degibbs.nii.gz' \\\n",
    "          --mask=$SUBJECTDIR'preprocessing/mask_for_eddy.nii.gz' \\\n",
    "          --index=$SUBJECTDIR'preprocessing/eddy_ind.txt' \\\n",
    "          --acqp=$SUBJECTDIR'preprocessing/eddy_config.txt' \\\n",
    "          --bvecs=$BVEC \\\n",
    "          --bvals=$BVAL \\\n",
    "          --out=$SUBJECTDIR'preprocessing/dwi_eddy' \\\n",
    "          --interp=trilinear \\\n",
    "          --data_is_shelled \\\n",
    "          --dont_peas;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ll dwi_eddy.*\n",
      "-rwxrwx--- 1 paquette users      2031 Jan 10 17:35 \"dwi_eddy.eddy_movement_rms\"*\n",
      "-rwxrwx--- 1 paquette users     12634 Jan 10 17:34 \"dwi_eddy.eddy_outlier_map\"*\n",
      "-rwxrwx--- 1 paquette users     52719 Jan 10 17:34 \"dwi_eddy.eddy_outlier_n_sqr_stdev_map\"*\n",
      "-rwxrwx--- 1 paquette users     52252 Jan 10 17:34 \"dwi_eddy.eddy_outlier_n_stdev_map\"*\n",
      "-rwxrwx--- 1 paquette users      2955 Jan 10 17:34 \"dwi_eddy.eddy_outlier_report\"*\n",
      "-rwxrwx--- 1 paquette users     16698 Jan 10 17:34 \"dwi_eddy.eddy_parameters\"*\n",
      "-rwxrwx--- 1 paquette users       637 Jan 10 17:34 \"dwi_eddy.eddy_post_eddy_shell_alignment_parameters\"*\n",
      "-rwxrwx--- 1 paquette users       480 Jan 10 17:33 \"dwi_eddy.eddy_post_eddy_shell_PE_translation_parameters\"*\n",
      "-rwxrwx--- 1 paquette users      2108 Jan 10 17:35 \"dwi_eddy.eddy_restricted_movement_rms\"*\n",
      "-rwxrwx--- 1 paquette users      2813 Jan 10 17:34 \"dwi_eddy.eddy_rotated_bvecs\"*\n",
      "-rwxrwx--- 1 paquette users 355669305 Jan 10 17:34 \"dwi_eddy.nii.gz\"*\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "# Let's have a look at the multiple output of eddy\n",
    "# It outputs various reports of motion correction, outlier detections, etc\n",
    "# the only important files are \n",
    "# dwi_eddy.nii.gz: the corrected data\n",
    "# dwi_eddy.eddy_rotated_bvecs: new bvecs taking the motion correction into account\n",
    "# those will be the bvecs we use for everything starting now.\n",
    "ll dwi_eddy.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
