{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DWI preprocessing\n",
    "## using MRTRIX, FSL and ANTS\n",
    "### by Michael Paquette\n",
    "#### Notes from Apr 7th"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this serie of bash notebook, I will be describing a basic DWI data preprocessing pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will try to stick to this (loose) general format to describe each step:  \n",
    "\n",
    "- What is the artefact we are trying to correct or the transformation we are trying to achieve  \n",
    "- Why does this happen  \n",
    "- What would happen if we didnt correct/modify \n",
    "- Why is this step here (somewhat arbitrary or specific ordering)  \n",
    "- Important parameters of the tool (and which one are likely to need finetuning)  \n",
    "- What to look for when doing QC (quality control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Like last time, we setup the basic variable with the folders\n",
      "ROOTDIR='/data/pt_02586/'\n",
      "SUBJECTDIR=$ROOTDIR'sub_01/'\n",
      "# and we move to the preprocessing folder\n",
      "cd $SUBJECTDIR'preprocessing'\n",
      "pwd\n",
      "/data/pt_02586/sub_01/preprocessing\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "# Like last time, we setup the basic variable with the folders\n",
    "ROOTDIR='/data/pt_02586/'\n",
    "SUBJECTDIR=$ROOTDIR'sub_01/'\n",
    "# and we move to the preprocessing folder\n",
    "cd $SUBJECTDIR'preprocessing'\n",
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick recap from March 24th\n",
    "\n",
    "We looked at the pratical example of tracking with 3 ROIs.  \n",
    "\n",
    "1. Launched 3 tractography with tckgen  \n",
    "- different ROI as seed for each  \n",
    "- Allows for equal number of seeds per ROI even with diffrent volume \n",
    "- We use only a basic tractography mask, no include/exclude mask\n",
    "\n",
    "2. Extract the bundles with tckedit  \n",
    "- We now apply the include/exclude mask (i.e. the ROIs)  \n",
    "- We have 3 pairs of ROIs, giving us 6 bundles  \n",
    "\n",
    "3. Combine the bundles with tckedit  \n",
    "- We recombine the bundles from same ROI pair\n",
    "- We also build a bigger bundle with all.  \n",
    "\n",
    "4. Compute track density image (TDI) with tckmap  \n",
    "- We compute the TDI on the full bundle, usefull for some viz and QC\n",
    "\n",
    "5. Project the FA on tracks with tcksample  \n",
    "- We project the FA map on the streamlines points and average per streamline  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Tractography with each SEED ROI\n",
    "\n",
    "tckgen fod_lmax6.nii.gz tracto/prob_seed_ifgop_large.tck \\\n",
    "  -algorithm iFOD2 \\\n",
    "  -step 1.0 \\\n",
    "  -angle 45 \\\n",
    "  -minlength 30 \\\n",
    "  -maxlength 250 \\\n",
    "  -seeds 1e7 \\\n",
    "  -seed_image ifgop_peak_dilx2_warped_fa_th0p2_bin0p25.nii.gz \\\n",
    "  -mask fa_eddy_th0p2.nii.gz \\\n",
    "  -nthreads 40\n",
    "\n",
    "tckgen fod_lmax6.nii.gz tracto/prob_seed_precg_large.tck \\\n",
    "  -algorithm iFOD2 \\\n",
    "  -step 1.0 \\\n",
    "  -angle 45 \\\n",
    "  -minlength 30 \\\n",
    "  -maxlength 250 \\\n",
    "  -seeds 1e7 \\\n",
    "  -seed_image precg_peak_dilx2_warped_fa_th0p2_bin0p25.nii.gz \\\n",
    "  -mask fa_eddy_th0p2.nii.gz \\\n",
    "  -nthreads 40\n",
    "\n",
    "tckgen fod_lmax6.nii.gz tracto/prob_seed_ptc_large.tck \\\n",
    "  -algorithm iFOD2 \\\n",
    "  -step 1.0 \\\n",
    "  -angle 45 \\\n",
    "  -minlength 30 \\\n",
    "  -maxlength 250 \\\n",
    "  -seeds 1e7 \\\n",
    "  -seed_image ptc_peak_dilx2_warped_fa_th0p2_bin0p25.nii.gz \\\n",
    "  -mask fa_eddy_th0p2.nii.gz \\\n",
    "  -nthreads 40\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. extract each bundle for each SEED \n",
    "\n",
    "tckedit tracto/prob_seed_ifgop_large.tck \\\n",
    "  tracto/prob_ifgop_precg_large.tck \\\n",
    "  -include ifgop_peak_dilx2_warped_fa_th0p2_bin0p25.nii.gz \\\n",
    "  -include precg_peak_dilx2_warped_fa_th0p2_bin0p25.nii.gz \\\n",
    "  -exclude ptc_peak_dilx2_warped_fa_th0p2_bin0p25.nii.gz \\\n",
    "  -nthreads 40\n",
    "\n",
    "tckedit tracto/prob_seed_ifgop_large.tck \\\n",
    "  tracto/prob_ifgop_ptc_large.tck \\\n",
    "  -include ifgop_peak_dilx2_warped_fa_th0p2_bin0p25.nii.gz \\\n",
    "  -include ptc_peak_dilx2_warped_fa_th0p2_bin0p25.nii.gz \\\n",
    "  -exclude precg_peak_dilx2_warped_fa_th0p2_bin0p25.nii.gz \\\n",
    "  -nthreads 40\n",
    "\n",
    "tckedit tracto/prob_seed_precg_large.tck \\\n",
    "  tracto/prob_precg_ptc_large.tck \\\n",
    "  -include precg_peak_dilx2_warped_fa_th0p2_bin0p25.nii.gz \\\n",
    "  -include ptc_peak_dilx2_warped_fa_th0p2_bin0p25.nii.gz \\\n",
    "  -exclude ifgop_peak_dilx2_warped_fa_th0p2_bin0p25.nii.gz \\\n",
    "  -nthreads 40\n",
    "\n",
    "tckedit tracto/prob_seed_precg_large.tck \\\n",
    "  tracto/prob_precg_ifgop_large.tck \\\n",
    "  -include ptc_peak_dilx2_warped_fa_th0p2_bin0p25.nii.gz \\\n",
    "  -include ifgop_peak_dilx2_warped_fa_th0p2_bin0p25.nii.gz \\\n",
    "  -exclude precg_peak_dilx2_warped_fa_th0p2_bin0p25.nii.gz \\\n",
    "  -nthreads 40\n",
    "\n",
    "tckedit tracto/prob_seed_ptc_large.tck \\\n",
    "  tracto/prob_ptc_ifgop_large.tck \\\n",
    "  -include ptc_peak_dilx2_warped_fa_th0p2_bin0p25.nii.gz \\\n",
    "  -include ifgop_peak_dilx2_warped_fa_th0p2_bin0p25.nii.gz \\\n",
    "  -exclude precg_peak_dilx2_warped_fa_th0p2_bin0p25.nii.gz \\\n",
    "  -nthreads 40\n",
    "\n",
    "tckedit tracto/prob_seed_ptc_large.tck \\\n",
    "  tracto/prob_ptc_precg_large.tck \\\n",
    "  -include ptc_peak_dilx2_warped_fa_th0p2_bin0p25.nii.gz \\\n",
    "  -include precg_peak_dilx2_warped_fa_th0p2_bin0p25.nii.gz \\\n",
    "  -exclude ifgop_peak_dilx2_warped_fa_th0p2_bin0p25.nii.gz \\\n",
    "  -nthreads 40\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Concatenate bundles\n",
    "\n",
    "tckedit tracto/prob_ifgop_precg_large.tck \\\n",
    "  tracto/prob_precg_ifgop_large.tck \\\n",
    "  tracto/prob_bundle_precg_ifgop_large.tck \\\n",
    "  -nthreads 40\n",
    "\n",
    "tckedit tracto/prob_ifgop_ptc_large.tck \\\n",
    "  tracto/prob_ptc_ifgop_large.tck \\\n",
    "  tracto/prob_bundle_ptc_ifgop_large.tck \\\n",
    "  -nthreads 40\n",
    "\n",
    "tckedit tracto/prob_precg_ptc_large.tck \\\n",
    "  tracto/prob_ptc_precg_large.tck \\\n",
    "  tracto/prob_bundle_ptc_precg_large.tck \\\n",
    "  -nthreads 40\n",
    "\n",
    "\n",
    "# concatenate all\n",
    "tckedit tracto/prob_ifgop_precg_large.tck \\\n",
    "  tracto/prob_precg_ifgop_large.tck \\\n",
    "  tracto/prob_ifgop_ptc_large.tck \\\n",
    "  tracto/prob_ptc_ifgop_large.tck \\\n",
    "  tracto/prob_precg_ptc_large.tck \\\n",
    "  tracto/prob_ptc_precg_large.tck \\\n",
    "  tracto/prob_bundles_large.tck \\\n",
    "  -nthreads 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. TDI map\n",
    "\n",
    "tckmap tracto/prob_bundles_large.tck tdi_prob_large.nii.gz \\\n",
    "  -template fa_eddy_th0p2.nii.gz \\\n",
    "  -contrast length\n",
    "\n",
    "# colored with orientation version\n",
    "tckmap tracto/prob_bundles_large.tck tdi_dec_prob_large.nii.gz \\\n",
    "  -template fa_eddy_th0p2.nii.gz \\\n",
    "  -dec \\\n",
    "  -contrast length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Project FA on streamlines\n",
    "\n",
    "tcksample tracto/prob_bundle_precg_ifgop_large_clean0p6.tck \\\n",
    "  fa_post_eddy.nii.gz \\\n",
    "  prob_bundle_precg_ifgop_large_clean0p6_meanFA.txt \\\n",
    "  -stat_tck mean\n",
    "\n",
    "tcksample tracto/prob_bundle_ptc_ifgop_large_clean0p6.tck \\\n",
    "  fa_post_eddy.nii.gz \\\n",
    "  prob_bundle_ptc_ifgop_large_clean0p6_meanFA.txt \\\n",
    "  -stat_tck mean\n",
    "\n",
    "tcksample tracto/prob_bundle_ptc_precg_large_clean0p6.tck \\\n",
    "  fa_post_eddy.nii.gz \\\n",
    "  prob_bundle_ptc_precg_large_clean0p6_meanFA.txt \\\n",
    "  -stat_tck mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual Connectome\n",
    "\n",
    "The previous method is suitable for this small task with only 3 ROIS.  \n",
    "We can \"afford\" to \"manually\" extract each bundle.  \n",
    "To get the streamline count without using something like python,  \n",
    "we STILL need to run something like tckinfo on each and note the counts.  \n",
    "\n",
    "However, in connectomics, we often have a full parcellation of the cortex.  \n",
    "This can easily be 150 ROIs per hemisphere. \n",
    "#### We need a systematic way to compute this matrix\n",
    "- Compute a labelmap image  \n",
    "- Combine tck, labelmap to compute trackcount connectome matrix  \n",
    "- Add metrics like length or FA  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tck2connectome\n",
    "https://mrtrix.readthedocs.io/en/latest/reference/commands/tck2connectome.html  \n",
    "https://mrtrix.readthedocs.io/en/dev/quantitative_structural_connectivity/structural_connectome.html  \n",
    "https://mrtrix.readthedocs.io/en/dev/quantitative_structural_connectivity/labelconvert_tutorial.html#labelconvert-tutorial  \n",
    "\n",
    "Tools for building connectome from streamlines and label map.  \n",
    "\n",
    "The links give information to build label map easier from other type of data, such as freesurfer cortex parcellation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tck2connectome -h | cat\n",
      "MRtrix 3.0.0                     tck2connectome                      Apr 23 2020\n",
      "\n",
      "     tck2connectome: part of the MRtrix3 package\n",
      "\n",
      "SYNOPSIS\n",
      "\n",
      "     Generate a connectome matrix from a streamlines file and a node\n",
      "     parcellation image\n",
      "\n",
      "USAGE\n",
      "\n",
      "     tck2connectome [ options ] tracks_in nodes_in connectome_out\n",
      "\n",
      "        tracks_in    the input track file\n",
      "\n",
      "        nodes_in     the input node parcellation image\n",
      "\n",
      "        connectome_out  the output .csv file containing edge weights\n",
      "\n",
      "\n",
      "EXAMPLE USAGES\n",
      "\n",
      "     Default usage:\n",
      "       $ tck2connectome tracks.tck nodes.mif connectome.csv -tck_weights_in weights.csv -out_assignments assignments.txt\n",
      "     By default, the metric of connectivity quantified in the connectome matrix\n",
      "     is the number of streamlines; or, if tcksift2 is used, the sum of\n",
      "     streamline weights via the -tck_weights_in option. Use of the\n",
      "     -out_assignments option is recommended as this enables subsequent use of\n",
      "     the connectome2tck command.\n",
      "\n",
      "     Generate a matrix consisting of the mean streamline length between each\n",
      "     node pair:\n",
      "       $ tck2connectome tracks.tck nodes.mif distances.csv -scale_length -stat_edge mean\n",
      "     By multiplying the contribution of each streamline to the connectome by\n",
      "     the length of that streamline, and then, for each edge, computing the mean\n",
      "     value across the contributing streamlines, one obtains a matrix where the\n",
      "     value in each entry is the mean length across those streamlines belonging\n",
      "     to that edge.\n",
      "\n",
      "     Generate a connectome matrix where the value of connectivity is the \"mean\n",
      "     FA\":\n",
      "       $ tcksample tracks.tck FA.mif mean_FA_per_streamline.csv -stat_tck mean; tck2connectome tracks.tck nodes.mif mean_FA_connectome.csv -scale_file mean_FA_per_streamline.csv -stat_edge mean\n",
      "     Here, a connectome matrix that is \"weighted by FA\" is generated in\n",
      "     multiple steps: firstly, for each streamline, the value of the underlying\n",
      "     FA image is sampled at each vertex, and the mean of these values is\n",
      "     calculated to produce a single scalar value of \"mean FA\" per streamline;\n",
      "     then, as each streamline is assigned to nodes within the connectome, the\n",
      "     magnitude of the contribution of that streamline to the matrix is\n",
      "     multiplied by the mean FA value calculated prior for that streamline;\n",
      "     finally, for each connectome edge, across the values of \"mean FA\" that\n",
      "     were contributed by all of the streamlines assigned to that particular\n",
      "     edge, the mean value is calculated.\n",
      "\n",
      "     Generate the connectivity fingerprint for streamlines seeded from a\n",
      "     particular region:\n",
      "       $ tck2connectome fixed_seed_tracks.tck nodes.mif fingerprint.csv -vector\n",
      "     This usage assumes that the streamlines being provided to the command have\n",
      "     all been seeded from the (effectively) same location, and as such, only\n",
      "     the endpoint of each streamline (not their starting point) is assigned\n",
      "     based on the provided parcellation image. Accordingly, the output file\n",
      "     contains only a vector of connectivity values rather than a matrix, since\n",
      "     each streamline is assigned to only one node rather than two.\n",
      "\n",
      "Structural connectome streamline assignment option\n",
      "\n",
      "  -assignment_end_voxels\n",
      "     use a simple voxel lookup value at each streamline endpoint\n",
      "\n",
      "  -assignment_radial_search radius\n",
      "     perform a radial search from each streamline endpoint to locate the\n",
      "     nearest node. Argument is the maximum radius in mm; if no node is found\n",
      "     within this radius, the streamline endpoint is not assigned to any node.\n",
      "     Default search distance is 4mm.\n",
      "\n",
      "  -assignment_reverse_search max_dist\n",
      "     traverse from each streamline endpoint inwards along the streamline, in\n",
      "     search of the last node traversed by the streamline. Argument is the\n",
      "     maximum traversal length in mm (set to 0 to allow search to continue to\n",
      "     the streamline midpoint).\n",
      "\n",
      "  -assignment_forward_search max_dist\n",
      "     project the streamline forwards from the endpoint in search of a\n",
      "     parcellation node voxel. Argument is the maximum traversal length in mm.\n",
      "\n",
      "  -assignment_all_voxels\n",
      "     assign the streamline to all nodes it intersects along its length (note\n",
      "     that this means a streamline may be assigned to more than two nodes, or\n",
      "     indeed none at all)\n",
      "\n",
      "Structural connectome metric options\n",
      "\n",
      "  -scale_length\n",
      "     scale each contribution to the connectome edge by the length of the\n",
      "     streamline\n",
      "\n",
      "  -scale_invlength\n",
      "     scale each contribution to the connectome edge by the inverse of the\n",
      "     streamline length\n",
      "\n",
      "  -scale_invnodevol\n",
      "     scale each contribution to the connectome edge by the inverse of the two\n",
      "     node volumes\n",
      "\n",
      "  -scale_file path\n",
      "     scale each contribution to the connectome edge according to the values in\n",
      "     a vector file\n",
      "\n",
      "Options for outputting connectome matrices\n",
      "\n",
      "  -symmetric\n",
      "     Make matrices symmetric on output\n",
      "\n",
      "  -zero_diagonal\n",
      "     Set matrix diagonal to zero on output\n",
      "\n",
      "Other options for tck2connectome\n",
      "\n",
      "  -stat_edge statistic\n",
      "     statistic for combining the values from all streamlines in an edge into a\n",
      "     single scale value for that edge (options are: sum,mean,min,max;\n",
      "     default=sum)\n",
      "\n",
      "  -tck_weights_in path\n",
      "     specify a text scalar file containing the streamline weights\n",
      "\n",
      "  -keep_unassigned\n",
      "     By default, the program discards the information regarding those\n",
      "     streamlines that are not successfully assigned to a node pair. Set this\n",
      "     option to keep these values (will be the first row/column in the output\n",
      "     matrix)\n",
      "\n",
      "  -out_assignments path\n",
      "     output the node assignments of each streamline to a file; this can be used\n",
      "     subsequently e.g. by the command connectome2tck\n",
      "\n",
      "  -vector\n",
      "     output a vector representing connectivities from a given seed point to\n",
      "     target nodes, rather than a matrix of node-node connectivities\n",
      "\n",
      "Standard options\n",
      "\n",
      "  -info\n",
      "     display information messages.\n",
      "\n",
      "  -quiet\n",
      "     do not display information messages or progress status; alternatively,\n",
      "     this can be achieved by setting the MRTRIX_QUIET environment variable to a\n",
      "     non-empty string.\n",
      "\n",
      "  -debug\n",
      "     display debugging messages.\n",
      "\n",
      "  -force\n",
      "     force overwrite of output files (caution: using the same file as input and\n",
      "     output might cause unexpected behaviour).\n",
      "\n",
      "  -nthreads number\n",
      "     use this number of threads in multi-threaded applications (set to 0 to\n",
      "     disable multi-threading).\n",
      "\n",
      "  -config key value  (multiple uses permitted)\n",
      "     temporarily set the value of an MRtrix config file entry.\n",
      "\n",
      "  -help\n",
      "     display this information page and exit.\n",
      "\n",
      "  -version\n",
      "     display version information and exit.\n",
      "\n",
      "AUTHOR\n",
      "     Robert E. Smith (robert.smith@florey.edu.au)\n",
      "\n",
      "COPYRIGHT\n",
      "     Copyright (c) 2008-2019 the MRtrix3 contributors.\n",
      "     This Source Code Form is subject to the terms of the Mozilla Public\n",
      "     License, v. 2.0. If a copy of the MPL was not distributed with this\n",
      "     file, You can obtain one at http://mozilla.org/MPL/2.0/.\n",
      "     Covered Software is provided under this License on an \"as is\"\n",
      "     basis, without warranty of any kind, either expressed, implied, or\n",
      "     statutory, including, without limitation, warranties that the\n",
      "     Covered Software is free of defects, merchantable, fit for a\n",
      "     particular purpose or non-infringing.\n",
      "     See the Mozilla Public License v. 2.0 for more details.\n",
      "     For more details, see http://www.mrtrix.org/.\n",
      "\n",
      "REFERENCES\n",
      "     If using the default streamline-parcel assignment mechanism (or\n",
      "     -assignment_radial_search option): Smith, R. E.; Tournier, J.-D.;\n",
      "     Calamante, F. & Connelly, A. The effects of SIFT on the reproducibility\n",
      "     and biological accuracy of the structural connectome. NeuroImage, 2015,\n",
      "     104, 253-265\n",
      "\n",
      "     If using -scale_invlength or -scale_invnodevol options: Hagmann, P.;\n",
      "     Cammoun, L.; Gigandet, X.; Meuli, R.; Honey, C.; Wedeen, V. & Sporns, O.\n",
      "     Mapping the Structural Core of Human Cerebral Cortex. PLoS Biology 6(7),\n",
      "     e159\n",
      "\n",
      "     Tournier, J.-D.; Smith, R. E.; Raffelt, D.; Tabbara, R.; Dhollander, T.;\n",
      "     Pietsch, M.; Christiaens, D.; Jeurissen, B.; Yeh, C.-H. & Connelly, A.\n",
      "     MRtrix3: A fast, flexible and open software framework for medical image\n",
      "     processing and visualisation. NeuroImage, 2019, 202, 116137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "tck2connectome -h | cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make label map manually\n",
    "# list of paths to individual ROI mask\n",
    "# ASSUMES non overlapping mask\n",
    "\n",
    "# KEEP this, maybe saved to a file, to \"remember\" ordering/mapping\n",
    "LABELROI=(path/to/mask1.nii.gz \\\n",
    "          path/to/mask2.nii.gz \\\n",
    "          path/to/mask3.nii.gz)\n",
    "\n",
    "# make empty label map \n",
    "mrcalc ${LABELROI[1]} 0 -mult labels.nii.gz\n",
    "\n",
    "# initialise ROI index\n",
    "ROIIDX=1\n",
    "\n",
    "# for each roimask\n",
    "for ROI in \"${LABELROI[@]}\"\n",
    "do\n",
    "    echo $ROI' index = '$ROIIDX;\n",
    "    # create a map of 0s and ROIIDX, add it to current labels\n",
    "    mrcalc $ROI $ROIIDX 0 -if labels.nii.gz -add labels.nii.gz -force;\n",
    "    # increment\n",
    "    ROIIDX=$((ROIIDX + 1))\n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
