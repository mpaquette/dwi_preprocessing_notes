{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DWI preprocessing\n",
    "## using MRTRIX, FSL and ANTS\n",
    "### by Michael Paquette\n",
    "#### Notes from Dec 15th"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this serie of bash notebook, I will be describing a basic DWI data preprocessing pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will try to stick to this (loose) general format to describe each step:  \n",
    "\n",
    "- What is the artefact we are trying to correct or the transformation we are trying to achieve  \n",
    "- Why does this happen  \n",
    "- What would happen if we didnt correct/modify \n",
    "- Why is this step here (somewhat arbitrary or specific ordering)  \n",
    "- Important parameters of the tool (and which one are likely to need finetuning)  \n",
    "- What to look for when doing QC (quality control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Like last time, we setup the basic variable with the folders\n",
      "ROOTDIR='/data/pt_02586/'\n",
      "SUBJECTDIR=$ROOTDIR'sub_01/'\n",
      "# and we move to the preprocessing folder\n",
      "cd $SUBJECTDIR'preprocessing'\n",
      "pwd\n",
      "/data/pt_02586/sub_01/preprocessing\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "# Like last time, we setup the basic variable with the folders\n",
    "ROOTDIR='/data/pt_02586/'\n",
    "SUBJECTDIR=$ROOTDIR'sub_01/'\n",
    "# and we move to the preprocessing folder\n",
    "cd $SUBJECTDIR'preprocessing'\n",
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BVEC=$SUBJECTDIR'preprocessing/bvecs.txt';\n",
      "BVAL=$SUBJECTDIR'preprocessing/bvals.txt';\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "BVEC=$SUBJECTDIR'preprocessing/bvecs.txt';\n",
    "BVAL=$SUBJECTDIR'preprocessing/bvals.txt';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Brain Mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are we correcting?\n",
    "We want to separate out the brain from the skull, surrounding tissue and background. \n",
    "#### Why does this happen?\n",
    "Many step perform better when we are only focusing on the brain rather than the full head and background. \n",
    "#### What if we ignore it?\n",
    "Various distorsion correction step will underperform or fail. \n",
    "#### Why correct it now?\n",
    "After denoising and degibbsing, we have sharper boundaries and we need to mask before moving on to distorsion correction. \n",
    "#### correction tools: dwiextract, mcflirt, N4BiasFieldCorrection, bet\n",
    "In this step, we will extract the b0s images from the full data using Mrtrix's dwiextract (this could be done with any tool that can select specific volumes out of the full data).  \n",
    "Then, we will use FSL's mcflirt to do some quick subject motion correction between the b0s (since they are typically aquired spread out in time).  \n",
    "We will average together the motion corrected b0s for maximal SNR.  \n",
    "Then, we will use ANTS' N4BiasFieldCorrection to artificially make the image more homogeonous in intensity, this will really help the brain mask tool since it work with image intensity gradients and threshold.  \n",
    "Finally, we will use FSL's BET (brain extraction tool) to create a mask of the brain.\n",
    "#### Quality control\n",
    "This step is heavy on manual quality control.  \n",
    "- After extracting the b0s, you should manually look through them to make sure there isnt a broken one, if so discard it.  \n",
    "- After motion correcting the b0s, you should make sure they all line up, otherwise the averaging step will fail.  \n",
    "- We apply the N4 image homogenisation step multiple times, \"as much as needed or until it doesnt change the image anymore\", this need to be decided by QC.  \n",
    "- Finally, the BET requires a threshold parameter (between 0 and 1) that need to be tune by hand, typically we compute multiple BET with different threshold and we find the right value by elimination; if the mask cuts part of the brain, make the threshold smaller, if the the mask still contain piece of skull and other, make the threshold bigger.\n",
    "\n",
    "#### This threshold can be different for different subject.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dwiextract can extract 3D volumes from diffusion data based on bvec/bval  \n",
    "We only need the \"-bzero\" flag here to extract all b0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We extract the b0 images from\n",
    "# the denoised and degibbs data\n",
    "# using dwiextract and the bval table\n",
    "# dwiextract can do more but the -bzero flag is what we need here\n",
    "dwiextract $SUBJECTDIR'preprocessing/dwi_denoise_degibbs.nii.gz' \\\n",
    "           $SUBJECTDIR'preprocessing/b0_denoise_degibbs.nii.gz' \n",
    "           -bzero \\\n",
    "           -fslgrad $BVEC $BVAL;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mcflirt corrects for motion by doing a simple linear registration.  \n",
    "We use the default tool which is a 6-dof (degree of freedom) registration (can be modified with the '-dof' flag)  \n",
    "We specify to which volume the others should be registered with the \"-refvol\" (reference volume) flag.  \n",
    "Most of time you will not care and use the first volume, if many volume are a bit messy you might want to chose the cleanest one has the reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mcflirt stands for Motion Correction flirt\n",
    "# flirt is the linear registration FSL tool\n",
    "# (FMRIB's Linear Image Registration Tool)\n",
    "fsl5.0-mcflirt -in $SUBJECTDIR'preprocessing/b0_denoise_degibbs.nii.gz' \\\n",
    "              -out $SUBJECTDIR'preprocessing/b0_denoise_degibbs_moco.nii.gz' \\\n",
    "              -stages 4 \\\n",
    "              -refvol 0;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We average all the motion corrected volume to get\n",
    "# a single 3D image\n",
    "mrmath $SUBJECTDIR'preprocessing/b0_denoise_degibbs_moco.nii.gz' \\\n",
    "       mean \\\n",
    "       $SUBJECTDIR'preprocessing/b0_avg_denoise_degibbs_moco.nii.gz' \\\n",
    "       -axis 3;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N4BiasFieldCorrection (or simply N4 bias correction) is an improvement of N3 (nonparameteric nonuniform normalization) bias correction.  \n",
    "It makes image more homogeneous in space.  \n",
    "We apply it many times until it converges (i.e. stops changing the image when reaplied)  \n",
    "We only want the create those artificially homogeonous images because it it easier to delimitate boundaries on them, we dont actually want to keep and use those images, only the mask they will produce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N4BiasFieldCorrection -d 3 \\\n",
    "     -i $SUBJECTDIR'preprocessing/b0_avg_denoise_degibbs_moco.nii.gz' \\\n",
    "     -o $SUBJECTDIR'preprocessing/b0_avg_denoise_degibbs_moco_N4x1.nii.gz';\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 mores application in this case.\n",
    "N4BiasFieldCorrection -d 3 -i $SUBJECTDIR'preprocessing/b0_avg_denoise_degibbs_moco_N4x1.nii.gz' -o $SUBJECTDIR'preprocessing/b0_avg_denoise_degibbs_moco_N4x2.nii.gz';\n",
    "N4BiasFieldCorrection -d 3 -i $SUBJECTDIR'preprocessing/b0_avg_denoise_degibbs_moco_N4x2.nii.gz' -o $SUBJECTDIR'preprocessing/b0_avg_denoise_degibbs_moco_N4x3.nii.gz';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BET (brain extraction tool) is a tool for segmenting brain from background (technically we use bet2, but not one uses bet1 anymore and bet2 is just bet now).  \n",
    "All the previous steps where simply used to provide a better input image to BET.  \n",
    "The b0 is used because it has clear contrast, much high SNR than diffusion and it is in the same space has the diffusion (contrary to the T1 image for example).  \n",
    "We motion corrected and averaged the b0s to get even more SNR.  \n",
    "And we N4'd them many time to maximize uniformity.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The '-m' flag generates the mask\n",
    "The '-n' flag makes it NOT generate the image with the skull removed (because I want to use the mask on OTHER data, the one that wasen't N4'd and the non-b0s volume)  \n",
    "The '-R' flag makes the bet \"robust\", it runs multiple time the estimation of the center of the brain for better accuracy.  \n",
    "The '-f 0.1' flag is critical parameter between 0 and 1 that need tuning, smaller numbers give bigger mask.  \n",
    "We will compute it with values 0.1, 0.3, 0.5, and 0.7 and select the best of them, i/e the one that doesn't include random pieces of skull and doesn't cut part of the brain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bet $SUBJECTDIR'preprocessing/b0_avg_denoise_degibbs_moco_N4x3.nii.gz' \\\n",
    "    $SUBJECTDIR'preprocessing/b0_avg_N4x3_bet_init_0p1.nii.gz' \\\n",
    "    -m \\\n",
    "    -n \\\n",
    "    -f 0.1 \\\n",
    "    -R;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 more times with different f threshold\n",
    "bet $SUBJECTDIR'preprocessing/b0_avg_denoise_degibbs_moco_N4x3.nii.gz' $SUBJECTDIR'preprocessing/b0_avg_N4x3_bet_init_0p3.nii.gz' -m -n -f 0.3 -R;\n",
    "bet $SUBJECTDIR'preprocessing/b0_avg_denoise_degibbs_moco_N4x3.nii.gz' $SUBJECTDIR'preprocessing/b0_avg_N4x3_bet_init_0p5.nii.gz' -m -n -f 0.5 -R;\n",
    "bet $SUBJECTDIR'preprocessing/b0_avg_denoise_degibbs_moco_N4x3.nii.gz' $SUBJECTDIR'preprocessing/b0_avg_N4x3_bet_init_0p7.nii.gz' -m -n -f 0.7 -R;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can write to a textfile that best choice to refer to it later\n",
    "read -p 'th: ' BETFOREDDY;\n",
    "touch betthforeddy.txt;\n",
    "echo $BETFOREDDY > betthforeddy.txt;\n",
    "# or you can copy/rename the best mask to some uniform name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All this work was to create a good mask for the next distorsion correction step, we will want to recompute a new mask after the distorsion correction, i.e. a better non distorted mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Also, since the data currently HAS distorsion, the mask CANNOT be too tight and perfect of it will cut out part of some volume, depending how distortedthere are and in which \"direction\" that distortion is, so in practice, the ACTUAL mask that will be used for the distorsion correction will be dilated version of the computed mask, i.e. we will add 1-2 voxels all around it to account for potential distortions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check bvec flip  \n",
    "- check weirdness in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DTI/FA on non-eddy corrected data\n",
    "dwi2tensor $SUBJECTDIR'preprocessing/dwi_denoise_degibbs.nii.gz' $SUBJECTDIR'preprocessing/dti_quick.nii.gz' -fslgrad $BVEC $BVAL;\n",
    "tensor2metric $SUBJECTDIR'preprocessing/dti_quick.nii.gz' -fa $SUBJECTDIR'preprocessing/fa_quick.nii.gz';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
